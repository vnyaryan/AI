# The provided code integrates several functionalities from the langchain library and the langchain_openai module to perform 
   #tasks related to document loading, text splitting, embedding generation, and similarity searches. 
    #Here's a breakdown and review of the key components and actions performed in the code:

# Imports: The code begins by importing necessary classes from langchain and langchain_openai. 
   #This setup allows for a variety of operations related to document processing and interaction with OpenAI's GPT models.

# API Key Setup: An example API key for OpenAI services is defined. It's correctly noted that in a production environment, 
   #this key should be managed securely (e.g., through environment variables or secure vaults) to prevent unauthorized access.

# OpenAIEmbeddings Instance: An instance of OpenAIEmbeddings is created using the provided API key. 
  #This instance will be used to generate embeddings, which are high-dimensional vectors representing text data. 
#These embeddings can be used for tasks like similarity searches or clustering.

# CharacterTextSplitter Instance: A CharacterTextSplitter object is configured to split text at newline characters with a specific chunk size 
 #and no overlap. This is useful for breaking down large text documents into more manageable pieces.

# TextLoader Instance: A TextLoader instance is created to load a text document from a specified path. This document will be processed further.

# Document Loading and Splitting: The document specified by the path is loaded and then split into chunks based on the 
   #configuration of the CharacterTextSplitter. This prepares the document for processing, such as embedding generation or similarity searches.

# Chroma Database Creation: A Chroma instance is created from the split documents. Chroma is a vector store that uses the 
  #embeddings generated by OpenAIEmbeddings to vectorize the documents. These vectors are stored in a specified directory for 
  #persistence and future similarity searches.

# Similarity Search: A similarity search is performed using the Chroma database to find documents related to a given query. 
   #This showcases the application of embeddings in retrieving relevant information based on semantic similarity.

# Results Iteration: Finally, the code iterates through the results of the similarity search, printing the content of each matched document. 
   #This could be used to display the findings to a user or further process the information.



# Importing the Chroma class from the langchain.vectorstores module for storing and searching vectors.
from langchain_community.vectorstores import Chroma

# Importing the ChatOpenAI class for generating chat responses using OpenAI's GPT models.
from langchain_openai import ChatOpenAI

# Importing CharacterTextSplitter for splitting text into chunks based on character count.
from langchain.text_splitter import CharacterTextSplitter

# Importing TextLoader for loading text documents into the program.
from langchain_community.document_loaders import TextLoader

# Importing OpenAIEmbeddings for generating embeddings using OpenAI's models.
from langchain_openai.embeddings import OpenAIEmbeddings

# Example API key for OpenAI services; replace with a real key in actual applications and store securely.
api_key = "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"

# Creating an instance of OpenAIEmbeddings with the provided API key for embedding generation.
embeddings = OpenAIEmbeddings(openai_api_key=api_key)

# Instantiating a CharacterTextSplitter object for splitting text at newline characters without overlapping.
text_splitter = CharacterTextSplitter(
    separator="\n",  # Sets the separator as the newline character.
    chunk_size=200,  # Sets the maximum size of each chunk to 200 characters.
    chunk_overlap=0  # Ensures that chunks do not overlap.
)

# Creating a TextLoader instance to load a text document from a specified file path.
loader = TextLoader("C:\\Users\\ARYAVIN\\Documents\\GitHub\\BOT\\UDEMY_PROJECT\\35\\facts\\facts.txt")

# Loading the document and splitting it into manageable chunks using the configured text splitter.
docs = loader.load_and_split(
    text_splitter=text_splitter  # Passing the text splitter configuration.
)

# Creating a Chroma instance from the split documents for vector storage and similarity searches.
db = Chroma.from_documents(
    docs,  # The split document chunks.
    embedding=embeddings,  # Using the previously created embeddings for vectorizing documents.
    persist_directory="emb"  # Directory where the vectors are stored persistently.
)

# Performing a similarity search in the Chroma database for documents related to the provided query.
results = db.similarity_search(
    "What is an interesting fact about the English language?"  # The query for similarity search.

)

# Iterating through the results of the similarity search and printing each result's content.
for result in results:
    print("\n")  # Printing a newline for better readability between results.
    print(result.page_content)  # Printing the content of the page for each result.
